{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "from mediapipe import solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "WIDTH, HEIGHT, CHANNELS = cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT), 3\n",
    "mp_face_mesh = solutions.face_mesh\n",
    "draw = solutions.drawing_utils\n",
    "drawing_spec = draw.DrawingSpec(color=(0, 255, 0), circle_radius=1, thickness=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp_face_mesh.FaceMesh() as face_mesh:\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            continue\n",
    "        op = face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) # modelo treinado com imagens no formato RGB\n",
    "        if op.multi_face_landmarks:\n",
    "            face_landmarks = op.multi_face_landmarks[0].landmark # objeto com todos os \"landmarks\" (pontos) do rosto\n",
    "            \n",
    "            ponto = draw._normalized_to_pixel_coordinates(face_landmarks[1].x, face_landmarks[1].y, WIDTH, HEIGHT) # Imagem com os pontos https://storage.googleapis.com/mediapipe-assets/documentation/mediapipe_face_landmark_fullsize.png\n",
    "\n",
    "            # cv2.rectangle(frame, ponto - np.array([5, 5]), ponto + np.array([5, 5]), color=(0, 255, 0)) # desenha um quadrado na posição da variável ponto\n",
    "\n",
    "            for landmarks in op.multi_face_landmarks: # op.multi_face_landmarks é uma lista que contém n listas de pontos (para n pessoas detectadas)\n",
    "                draw.draw_landmarks(frame, landmarks, mp_face_mesh.FACEMESH_CONTOURS, landmark_drawing_spec=drawing_spec) # desenha os pontos no frame\n",
    "\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estima os ângulos nos eixos de rotação x, y e z\n",
    "# adaptado de https://github.com/niconielsen32/ComputerVision/blob/master/headPoseEstimation.py\n",
    "\n",
    "with mp_face_mesh.FaceMesh() as face_mesh:\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            continue\n",
    "        op = face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) # modelo treinado com imagens no formato RGB\n",
    "        face_2d, face_3d = [], []\n",
    "        if op.multi_face_landmarks:\n",
    "            for landmarks in op.multi_face_landmarks: # op.multi_face_landmarks é uma lista que contém n listas de pontos (para n pessoas detectadas)\n",
    "                for id, landmark in enumerate(landmarks.landmark):\n",
    "                    if id in (1, 33, 61, 199, 263, 291): # 1: ponta do nariz; 33: canto esquerdo do olho esquerdo; 61: canto esquerdo da boca; 199: meio do queixo; 263: canto direito do olho direito; 291: canto direito da boca\n",
    "                        if id == 1:\n",
    "                            nose_2d = landmark.x*WIDTH, landmark.y*HEIGHT\n",
    "                            nose_3d = landmark.x*WIDTH, landmark.y*HEIGHT, landmark.z*WIDTH\n",
    "                        x, y = int(landmark.x*WIDTH), int(landmark.y*HEIGHT)\n",
    "\n",
    "                        face_2d.append((x, y))\n",
    "                        face_3d.append((x, y, landmark.z))\n",
    "                \n",
    "                face_2d = np.array(face_2d, dtype=np.float64)\n",
    "                face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "                focal_width = WIDTH\n",
    "                camera_matrix = np.array([[focal_width, 0, HEIGHT/2],\n",
    "                                          [0, focal_width, HEIGHT/2],\n",
    "                                          [0, 0, 1]])\n",
    "                distortion_matrix = np.zeros((4, 1), np.float64)\n",
    "                success, rot_vec, trans_vec = cv2.solvePnP(face_3d, face_2d, camera_matrix, distortion_matrix)\n",
    "                rotation_matrix, jacobian = cv2.Rodrigues(rot_vec)\n",
    "                angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rotation_matrix)\n",
    "                x = angles[0]*360\n",
    "                y = angles[1]*360\n",
    "                z = angles[2]*360\n",
    "                \n",
    "                cv2.putText(frame, \"x: \" + str(np.round(x,2)), (500, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"y: \" + str(np.round(y,2)), (500, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"z: \" + str(np.round(z,2)), (500, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "                draw.draw_landmarks(frame, landmarks, mp_face_mesh.FACEMESH_CONTOURS, landmark_drawing_spec=drawing_spec)\n",
    "\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
