{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "from mediapipe import solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "WIDTH, HEIGHT, CHANNELS = cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT), 3\n",
    "mp_face_mesh = solutions.face_mesh\n",
    "draw = solutions.drawing_utils\n",
    "drawing_spec = draw.DrawingSpec(color=(0, 255, 0), circle_radius=1, thickness=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/nikolas/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "with mp_face_mesh.FaceMesh() as face_mesh:\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            continue\n",
    "        op = face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) # modelo treinado com imagens no formato RGB\n",
    "        if op.multi_face_landmarks:\n",
    "            face_landmarks = op.multi_face_landmarks[0].landmark # objeto com todos os \"landmarks\" (pontos) do rosto\n",
    "            \n",
    "            ponto = draw._normalized_to_pixel_coordinates(face_landmarks[1].x, face_landmarks[1].y, WIDTH, HEIGHT) # Imagem com os pontos https://storage.googleapis.com/mediapipe-assets/documentation/mediapipe_face_landmark_fullsize.png\n",
    "\n",
    "            # cv2.rectangle(frame, ponto - np.array([5, 5]), ponto + np.array([5, 5]), color=(0, 255, 0)) # desenha um quadrado na posição da variável ponto\n",
    "\n",
    "            for landmarks in op.multi_face_landmarks: # op.multi_face_landmarks é uma lista que contém n listas de pontos (para n pessoas detectadas)\n",
    "                draw.draw_landmarks(frame, landmarks, mp_face_mesh.FACEMESH_CONTOURS, landmark_drawing_spec=drawing_spec) # desenha os pontos no frame\n",
    "\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Landmark:\n",
    "    NOSE = 1\n",
    "    LEFT_EYE = 33\n",
    "    LEFT_MOUTH = 61\n",
    "    CHIN = 199\n",
    "    RIGHT_EYE = 263\n",
    "    RIGHT_MOUTH = 291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estima os ângulos nos eixos de rotação x, y e z\n",
    "# adaptado de https://github.com/niconielsen32/ComputerVision/blob/master/headPoseEstimation.py e de https://stackoverflow.com/questions/69039324/head-pose-estimation-using-facial-landmarks\n",
    "\n",
    "face_3d = np.array([            # Posição aproximada dos pontos\n",
    "    (0.0, 0.0, 0.0),            # NOSE\n",
    "    (0.0, -200.0, -65.0),       # CHIN\n",
    "    (-150.0, 170.0, -135.0),    # LEFT_EYE\n",
    "    (150.0, 170.0, -135.0),     # RIGHT_EYE\n",
    "    (-150.0, -150.0, -125.0),   # LEFT_MOUTH\n",
    "    (150.0, -150.0, -125.0)     # RIGHT_MOUTH\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "distortion_matrix = np.zeros((4, 1 )) # No lens distortion\n",
    "FOCAL_LENGTH = WIDTH\n",
    "camera_matrix = np.array(\n",
    "    [[FOCAL_LENGTH, 0, WIDTH/2],\n",
    "     [0, FOCAL_LENGTH, HEIGHT/2],\n",
    "     [0, 0, 1]], dtype=np.float64\n",
    ")\n",
    "dist = []\n",
    "\n",
    "with mp_face_mesh.FaceMesh() as face_mesh:\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            continue\n",
    "        op = face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) # modelo treinado com imagens no formato RGB\n",
    "        face_2d = []\n",
    "        if op.multi_face_landmarks:\n",
    "            for landmarks in op.multi_face_landmarks: # op.multi_face_landmarks é uma lista que contém n listas de pontos (para n pessoas detectadas)\n",
    "                for id, landmark in enumerate(landmarks.landmark):\n",
    "                    # if id == Landmark.NOSE:\n",
    "                    #     nose_2d = landmark.x*WIDTH, landmark.y*HEIGHT\n",
    "                    x, y = int(landmark.x*WIDTH), int(landmark.y*HEIGHT)\n",
    "\n",
    "                    face_2d.append((x, y))\n",
    "                \n",
    "                points_of_interest = np.array([\n",
    "                    face_2d[Landmark.NOSE],\n",
    "                    face_2d[Landmark.CHIN],\n",
    "                    face_2d[Landmark.LEFT_EYE],\n",
    "                    face_2d[Landmark.RIGHT_EYE],\n",
    "                    face_2d[Landmark.LEFT_MOUTH],\n",
    "                    face_2d[Landmark.RIGHT_MOUTH]\n",
    "                ], dtype=np.float64)\n",
    "\n",
    "                # max_XY = max(face_2d, key=lambda p: p[0])[0], max(face_2d, key=lambda p: p[1])[1]\n",
    "                # min_XY = min(face_2d, key=lambda p: p[0])[0], min(face_2d, key=lambda p: p[1])[1]\n",
    "\n",
    "                # xcenter = (max_XY[0] + min_XY[0]) / 2\n",
    "                # ycenter = (max_XY[1] + min_XY[1]) / 2\n",
    "\n",
    "                # dist.append((int(((xcenter-WIDTH/2)**2+(ycenter-HEIGHT/2)**2)**0.4), max_XY, min_XY))\n",
    "                \n",
    "                success, rot_vec, trans_vec = cv2.solvePnP(face_3d, points_of_interest, camera_matrix, distortion_matrix)\n",
    "                rotation_matrix, jacobian = cv2.Rodrigues(rot_vec)\n",
    "                angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rotation_matrix)\n",
    "                x = angles[0]-np.sign(angles[0])*180\n",
    "                y = angles[1]\n",
    "                z = angles[2]\n",
    "                \n",
    "                cv2.putText(frame, f\"x: {str(np.round(x,2))}\", (0, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                cv2.putText(frame, f\"y: {str(np.round(y,2))}\", (0, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                cv2.putText(frame, f\"z: {str(np.round(z,2))}\", (0, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "                draw.draw_landmarks(frame, landmarks, mp_face_mesh.FACEMESH_CONTOURS, landmark_drawing_spec=drawing_spec)\n",
    "\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
